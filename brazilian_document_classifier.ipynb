{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Brazilian Document Classification (Kaggle)\n",
        "\n",
        "**Plan:** 60% training, 40% held-out testing. Predict document type (8–9 classes).\n",
        "\n",
        "Logic adapted from [identity-document-image-classification](https://github.com/leomaurodesenv/kaggle) (BID dataset).\n",
        "\n",
        "1. Add your dataset in Kaggle Input (folder per class: CNH_Frente, CPF_Frente, RG_Frente, etc.)\n",
        "2. Set `DATA_PATH` below to your dataset path\n",
        "3. Run all cells (enable GPU in Settings → Accelerator)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Config - EfficientNet-B7, 60/40 split, Kaggle-ready\n",
        "DATA_PATH = \"/kaggle/input/bid-dataset\"  # Kaggle: Bid_dataset. If zip, may need /kaggle/input/bid-dataset/BID Sample Dataset\n",
        "TRAIN_RATIO = 0.60\n",
        "RANDOM_SEED = 42\n",
        "BATCH_SIZE = 16  # B7 is memory-heavy; reduce to 8 if OOM on Kaggle\n",
        "IMG_SIZE = (224, 224)  # ResNet standard input\n",
        "EPOCHS = 5\n",
        "LR = 1e-3\n",
        "EARLY_STOP_PATIENCE = 20\n",
        "EARLY_STOP_MIN_DELTA = 0.001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 60/40 split - BID dataset compatible (excludes _ocr.txt, _segmentation.jpg)\n",
        "def load_and_split(data_path, train_ratio=0.60, seed=42, exclude_patterns=(\"_ocr\", \"_segmentation\")):\n",
        "    data_path = Path(data_path)\n",
        "    classes = sorted([d.name for d in data_path.iterdir() if d.is_dir()])\n",
        "    class_to_idx = {c: i for i, c in enumerate(classes)}\n",
        "    train_samples, test_samples = [], []\n",
        "    for cls in classes:\n",
        "        imgs = [p for p in (data_path / cls).glob(\"*\") \n",
        "                if p.suffix.lower() in (\".jpg\", \".jpeg\", \".png\", \".bmp\")\n",
        "                and not any(ex in p.stem for ex in exclude_patterns)]\n",
        "        if not imgs:\n",
        "            continue\n",
        "        tr, te = train_test_split(imgs, train_size=train_ratio, random_state=seed)\n",
        "        train_samples += [(str(p), class_to_idx[cls]) for p in tr]\n",
        "        test_samples += [(str(p), class_to_idx[cls]) for p in te]\n",
        "    return train_samples, test_samples, class_to_idx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class DocumentDataset(Dataset):\n",
        "    def __init__(self, samples, transform=None):\n",
        "        self.samples = samples\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path, label = self.samples[idx]\n",
        "        img = Image.open(path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Transforms - ImageNet norm for pretrained ResNet; augmentation for robustness\n",
        "def get_transforms(img_size, is_train=True):\n",
        "    norm = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    if is_train:\n",
        "        return transforms.Compose([\n",
        "            transforms.Resize(img_size),\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.RandomVerticalFlip(p=0.5),\n",
        "            transforms.RandomRotation(15),\n",
        "            transforms.RandomAffine(0, scale=(0.95, 1.05)),\n",
        "            transforms.ToTensor(),\n",
        "            norm,\n",
        "        ])\n",
        "    return transforms.Compose([transforms.Resize(img_size), transforms.ToTensor(), norm])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Resolve path (Kaggle zip may extract to subfolder e.g. \"BID Sample Dataset\")\n",
        "_data_path = Path(DATA_PATH)\n",
        "if _data_path.exists():\n",
        "    subdirs = [d for d in _data_path.iterdir() if d.is_dir()]\n",
        "    class_names = [d.name for d in subdirs]\n",
        "    if len(subdirs) == 1 and not any(c.startswith(\"CNH\") or c.startswith(\"CPF\") or c.startswith(\"RG\") for c in class_names):\n",
        "        DATA_PATH = str(subdirs[0])\n",
        "        print(f\"Using subfolder: {DATA_PATH}\")\n",
        "\n",
        "train_samples, test_samples, class_to_idx = load_and_split(DATA_PATH, TRAIN_RATIO, RANDOM_SEED)\n",
        "if len(train_samples) == 0:\n",
        "    _list = list(Path(DATA_PATH).iterdir()) if Path(DATA_PATH).exists() else \"path not found\"\n",
        "    raise ValueError(f\"No images at {DATA_PATH}. Expected CNH_Frente, CPF_Frente, RG_Frente folders. Contents: {_list}\")\n",
        "num_classes = len(class_to_idx)\n",
        "print(f\"Classes: {list(class_to_idx.keys())}\")\n",
        "print(f\"Train: {len(train_samples)} | Test: {len(test_samples)} (40% held-out)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "train_ds = DocumentDataset(train_samples, get_transforms(IMG_SIZE, is_train=True))\n",
        "test_ds = DocumentDataset(test_samples, get_transforms(IMG_SIZE, is_train=False))\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
        "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# EfficientNet-B7 - pretrained, high-accuracy document classification\n",
        "model = models.efficientnet_b7(weights=models.EfficientNet_B7_Weights.IMAGENET1K_V1)\n",
        "model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
        "model = model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Train on 60% only (with early stopping from identity-document notebook)\n",
        "best_loss = float(\"inf\")\n",
        "patience_counter = 0\n",
        "best_state = None\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total, correct, total_loss = 0, 0, 0.0\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(imgs)\n",
        "        loss = criterion(out, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        correct += (out.argmax(1) == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    acc = 100 * correct / total\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} | Loss: {avg_loss:.4f} | Train Acc: {acc:.2f}%\")\n",
        "\n",
        "    if avg_loss < best_loss - EARLY_STOP_MIN_DELTA:\n",
        "        best_loss = avg_loss\n",
        "        patience_counter = 0\n",
        "        best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= EARLY_STOP_PATIENCE:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            if best_state:\n",
        "                model.load_state_dict(best_state)\n",
        "                model = model.to(device)\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Evaluate on 40% held-out test set\n",
        "model.eval()\n",
        "correct, total = 0, 0\n",
        "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
        "class_correct = {i: 0 for i in range(num_classes)}\n",
        "class_total = {i: 0 for i in range(num_classes)}\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in test_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        out = model(imgs)\n",
        "        pred = out.argmax(1)\n",
        "        correct += (pred == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "        for l, p in zip(labels, pred):\n",
        "            class_total[l.item()] += 1\n",
        "            if l.item() == p.item():\n",
        "                class_correct[l.item()] += 1\n",
        "\n",
        "acc = 100 * correct / total\n",
        "print(\"=\"*50)\n",
        "print(\"Test Set Accuracy (40% held-out)\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Overall: {acc:.2f}% ({correct}/{total})\")\n",
        "for i in range(num_classes):\n",
        "    c_acc = 100 * class_correct[i] / class_total[i] if class_total[i] else 0\n",
        "    print(f\"  {idx_to_class[i]}: {c_acc:.2f}%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Save model\n",
        "torch.save({\n",
        "    \"model_state\": model.state_dict(),\n",
        "    \"class_to_idx\": class_to_idx,\n",
        "    \"num_classes\": num_classes,\n",
        "    \"arch\": \"efficientnet_b7\",\n",
        "}, \"/kaggle/working/document_classifier.pt\")\n",
        "print(\"Model saved to /kaggle/working/document_classifier.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}